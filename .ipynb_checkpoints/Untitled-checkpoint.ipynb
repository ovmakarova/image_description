{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import code\n",
    "import os\n",
    "import cPickle as pickle\n",
    "import math\n",
    "import scipy.io\n",
    "\n",
    "from imagernn.solver import Solver\n",
    "from imagernn.imagernn_utils import decodeGenerator, eval_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint D:/HSE/neuraltalk/flickr8k_cnn_lstm_v1.p\n"
     ]
    }
   ],
   "source": [
    "# load the checkpoint\n",
    "root_path = \"D:/HSE/neuraltalk/\"\n",
    "checkpoint_path = root_path + \"flickr8k_cnn_lstm_v1.p\"\n",
    "print 'loading checkpoint %s' % (checkpoint_path, )\n",
    "checkpoint = pickle.load(open(checkpoint_path, 'rb'))\n",
    "checkpoint_params = checkpoint['params']\n",
    "dataset = checkpoint_params['dataset']\n",
    "model = checkpoint['model']\n",
    "misc = {}\n",
    "misc['wordtoix'] = checkpoint['wordtoix']\n",
    "ixtoword = checkpoint['ixtoword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output blob which we will dump to JSON for visualizing the results\n",
    "blob = {} \n",
    "# blob['params'] = params\n",
    "blob['checkpoint_params'] = checkpoint_params\n",
    "blob['imgblobs'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tasks.txt file\n",
    "\n",
    "img_names = open(os.path.join(root_path + \"example_images\", 'tasks.txt'), 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the features for all images\n",
    "features_path = os.path.join(root_path, 'vgg_feats.mat')\n",
    "features_struct = scipy.io.loadmat(features_path)\n",
    "features = features_struct['feats'] # this is a 4096 x N numpy array of features\n",
    "D,N = features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 0/16:\n",
      "PRED: (-7.245608) a dog plays with a toy\n",
      "image 1/16:\n",
      "PRED: (-6.825829) a dog runs through a field\n",
      "image 2/16:\n",
      "PRED: (-6.071394) a dog runs through the woods\n",
      "image 3/16:\n",
      "PRED: (-7.696322) a dog plays with a toy\n",
      "image 4/16:\n",
      "PRED: (-10.154738) a man and a woman sit on a bench\n",
      "image 5/16:\n",
      "PRED: (-7.413065) a dog plays with a toy\n",
      "image 6/16:\n",
      "PRED: (-10.011646) a black and white dog is climbing a tree\n",
      "image 7/16:\n",
      "PRED: (-11.486791) a child in a red jacket is standing in the snow\n",
      "image 8/16:\n",
      "PRED: (-11.969720) a man in a white shirt is playing a guitar\n",
      "image 9/16:\n",
      "PRED: (-8.722684) a man and a woman are posing for a picture\n",
      "image 10/16:\n",
      "PRED: (-6.831288) a group of people pose for a picture\n",
      "image 11/16:\n",
      "PRED: (-9.867244) a man and a woman sit at a table\n",
      "image 12/16:\n",
      "PRED: (-8.609164) a man and a woman sit on a bench\n",
      "image 13/16:\n",
      "PRED: (-9.136447) a man is standing in the water\n",
      "image 14/16:\n",
      "PRED: (-8.172481) a group of people are gathered together\n",
      "image 15/16:\n",
      "PRED: (-8.821453) a man and a woman pose for a picture\n"
     ]
    }
   ],
   "source": [
    "# iterate over all images and predict sentences\n",
    "BatchGenerator = decodeGenerator(checkpoint_params)\n",
    "for n in xrange(N):\n",
    "    print 'image %d/%d:' % (n, N)\n",
    "\n",
    "    # encode the image\n",
    "    img = {}\n",
    "    img['feat'] = features[:, n]\n",
    "    img['local_file_path'] =img_names[n]\n",
    "\n",
    "    # perform the work. heavy lifting happens inside\n",
    "    kwparams = { 'beam_size' : 20 }\n",
    "    Ys = BatchGenerator.predict([{'image':img}], model, checkpoint_params, **kwparams)\n",
    "\n",
    "    # build up the output\n",
    "    img_blob = {}\n",
    "    img_blob['img_path'] = img['local_file_path']\n",
    "\n",
    "    # encode the top prediction\n",
    "    top_predictions = Ys[0] # take predictions for the first (and only) image we passed in\n",
    "    top_prediction = top_predictions[0] # these are sorted with highest on top\n",
    "    candidate = ' '.join([ixtoword[ix] for ix in top_prediction[1] if ix > 0]) # ix 0 is the END token, skip that\n",
    "    print 'PRED: (%f) %s' % (top_prediction[0], candidate)\n",
    "    img_blob['candidate'] = {'text': candidate, 'logprob': top_prediction[0]}    \n",
    "    blob['imgblobs'].append(img_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions to D:/HSE/neuraltalk/example_images\\result_struct.json...\n"
     ]
    }
   ],
   "source": [
    "# dump result struct to file\n",
    "save_file = os.path.join(root_path, 'result_struct.json')\n",
    "print 'writing predictions to %s...' % (save_file, )\n",
    "json.dump(blob, open(save_file, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing html result file to D:/HSE/neuraltalk/example_images\\result.html...\n"
     ]
    }
   ],
   "source": [
    "# dump output html\n",
    "html = ''\n",
    "for img in blob['imgblobs']:\n",
    "    html += '<img src=\"%s\" height=\"400\"><br>' % (img['img_path'], )\n",
    "    html += '(%f) %s <br><br>' % (img['candidate']['logprob'], img['candidate']['text'])\n",
    "html_file = os.path.join(root_path, 'result.html')\n",
    "print 'writing html result file to %s...' % (html_file, )\n",
    "open(html_file, 'w').write(html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
